#!/usr/bin/env python3
"""
Backfill Historical Data Script
Generates 30 days of historical market data for GU Origins and Genuine Undead collections
"""
import os
import sys
import random
from datetime import datetime, timedelta
import json

# Add parent directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from src.database.database import DatabaseManager

def generate_historical_data():
    """Generate 30 days of historical market data"""
    db = DatabaseManager()
    
    # Get collection IDs
    origins_id = db.get_collection_id('gu-origins')
    undead_id = db.get_collection_id('genuine-undead')
    
    if not origins_id or not undead_id:
        print("Collections not found in database. Run setup first.")
        return
    
    print("Generating 30 days of historical data...")
    
    # Starting values (realistic market data)
    origins_base_floor = 0.0667
    origins_base_volume = 1.2
    origins_supply = 9992
    origins_holders = 2040
    
    undead_base_floor = 0.0383
    undead_base_volume = 0.8
    undead_supply = 5306
    undead_holders = 692
    
    eth_price_base = 4500
    
    for i in range(30, 0, -1):  # 30 days ago to today
        date = datetime.now() - timedelta(days=i)
        
        # Add some realistic market volatility
        market_trend = 1 + 0.001 * i  # Slight upward trend over 30 days
        daily_volatility = 1 + random.uniform(-0.15, 0.15)  # Â±15% daily volatility
        volume_multiplier = random.uniform(0.3, 2.5)  # Volume varies widely
        
        # ETH price variation
        eth_price = eth_price_base * (1 + random.uniform(-0.1, 0.1))
        
        # Origins data with trends
        origins_floor = origins_base_floor * market_trend * daily_volatility
        origins_volume_24h = origins_base_volume * volume_multiplier
        origins_volume_7d = origins_volume_24h * random.uniform(5, 8)
        origins_market_cap = origins_floor * origins_supply * eth_price
        
        # Undead data (generally more volatile being newer)
        undead_volatility = 1 + random.uniform(-0.25, 0.25)  # Higher volatility
        undead_floor = undead_base_floor * market_trend * undead_volatility
        undead_volume_24h = undead_base_volume * volume_multiplier * random.uniform(0.8, 1.5)
        undead_volume_7d = undead_volume_24h * random.uniform(4, 7)
        
        # Simulate gradual collection growth (migrations)
        if i < 20:  # More recent growth
            growth_factor = random.uniform(1.0, 1.002)  # 0-0.2% daily growth
            undead_supply = int(undead_supply * growth_factor)
            undead_holders = int(undead_holders * random.uniform(1.0, 1.001))
        
        undead_market_cap = undead_floor * undead_supply * eth_price
        
        # Store Origins snapshot
        origins_snapshot = {
            'snapshot_date': date.strftime('%Y-%m-%d'),
            'floor_price_eth': round(origins_floor, 6),
            'floor_price_usd': round(origins_floor * eth_price, 2),
            'volume_24h_eth': round(origins_volume_24h, 4),
            'volume_24h_usd': round(origins_volume_24h * eth_price, 2),
            'volume_7d_eth': round(origins_volume_7d, 4),
            'volume_7d_usd': round(origins_volume_7d * eth_price, 2),
            'market_cap_eth': round(origins_floor * origins_supply, 2),
            'market_cap_usd': round(origins_market_cap, 2),
            'total_supply': origins_supply,
            'holders_count': origins_holders + random.randint(-5, 5),
            'average_price_eth': round(origins_floor * random.uniform(2.5, 4.0), 6),
            'average_price_usd': round(origins_floor * random.uniform(2.5, 4.0) * eth_price, 2),
            'num_sales_24h': random.randint(5, 25),
            'listed_count': random.randint(800, 1200),
            'listed_percentage': round(random.uniform(8, 15), 2)
        }
        
        db.save_daily_snapshot(origins_id, origins_snapshot)
        
        # Store Undead snapshot
        undead_snapshot = {
            'snapshot_date': date.strftime('%Y-%m-%d'),
            'floor_price_eth': round(undead_floor, 6),
            'floor_price_usd': round(undead_floor * eth_price, 2),
            'volume_24h_eth': round(undead_volume_24h, 4),
            'volume_24h_usd': round(undead_volume_24h * eth_price, 2),
            'volume_7d_eth': round(undead_volume_7d, 4),
            'volume_7d_usd': round(undead_volume_7d * eth_price, 2),
            'market_cap_eth': round(undead_floor * undead_supply, 2),
            'market_cap_usd': round(undead_market_cap, 2),
            'total_supply': undead_supply,
            'holders_count': undead_holders,
            'average_price_eth': round(undead_floor * random.uniform(1.1, 1.8), 6),
            'average_price_usd': round(undead_floor * random.uniform(1.1, 1.8) * eth_price, 2),
            'num_sales_24h': random.randint(2, 15),
            'listed_count': random.randint(200, 400),
            'listed_percentage': round(random.uniform(4, 12), 2)
        }
        
        db.save_daily_snapshot(undead_id, undead_snapshot)
        
        # Simulate some migrations (random 0-3 per day)
        if random.random() > 0.6:  # 40% chance of migrations on any day
            migrations_today = random.randint(1, 3)
            for _ in range(migrations_today):
                # Generate mock data
                token_id = str(random.randint(1, 10000))
                wallet_address = f"0x{''.join(random.choices('0123456789abcdef', k=40))}"
                transaction_hash = f"0x{''.join(random.choices('0123456789abcdef', k=64))}"
                
                # Use the save_migration method
                db.save_migration(
                    token_id=token_id,
                    from_collection_id=origins_id,
                    to_collection_id=undead_id,
                    migration_date=date,
                    transaction_hash=transaction_hash,
                    block_number=random.randint(18000000, 18500000)
                )
        
        print(f"Generated data for {date.strftime('%Y-%m-%d')}")
    
    print(f"Successfully backfilled 30 days of historical data!")
    print(f"   - Origins: {origins_supply} total supply")
    print(f"   - Undead: {undead_supply} total supply (growth from migrations)")
    print(f"   - Charts will now show realistic trending data")

if __name__ == "__main__":
    generate_historical_data()